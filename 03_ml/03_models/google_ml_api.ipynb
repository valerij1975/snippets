{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2f0408-6065-463b-a826-639125d2259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-language\n",
      "  Downloading google_cloud_language-2.8.1-py2.py3-none-any.whl (88 kB)\n",
      "     ---------------------------------------- 88.4/88.4 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-cloud-language) (4.21.12)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-cloud-language) (2.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-cloud-language) (1.22.2)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (2.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (1.58.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\user\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (2.28.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (1.51.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (1.51.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (3.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-language) (0.4.8)\n",
      "Installing collected packages: google-cloud-language\n",
      "Successfully installed google-cloud-language-2.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade google-cloud-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7981b4c6-71ae-4217-afb1-8113d2c022d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import language_v1\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa381e-4e2c-4a71-bfd0-1cf68cb33696",
   "metadata": {},
   "source": [
    "# Google Natural Language API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae2781-99d6-47b3-b71d-c9c5f8c8a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_SERVICE_ACCOUNT_JSON='celestial-digit-0000000000.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5991a67-efeb-4c82-bac8-39660479bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99224, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "\n",
       "   review_score review_comment_title review_comment_message  \\\n",
       "0             4                 None                   None   \n",
       "1             5                 None                   None   \n",
       "\n",
       "  review_creation_date review_answer_timestamp  \n",
       "0  2018-01-18 00:00:00     2018-01-18 21:46:59  \n",
       "1  2018-03-10 00:00:00     2018-03-11 03:05:13  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='../../data/olist'\n",
    "df = pd.read_parquet(os.path.join(PATH, 'olist_order_reviews_dataset.parquet'))\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c7f319-97ee-4985-9e00-2f109a6ea4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ebe66710034a56adc9ed31c1c60e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['C']=df.progress_apply(lambda x: (\"\" if pd.isna(x['review_comment_title']) else str(x['review_comment_title']) + '. ')\\\n",
    "                                 + (\"\" if pd.isna(x['review_comment_message']) else str(x['review_comment_message'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c66e4e-cff8-4d08-8f77-befb2f5790d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count reviews to send to API:  42706\n",
      "Forecast cost of processing, usd:  94.26500000000001\n"
     ]
    }
   ],
   "source": [
    "count_reviews=df.apply(lambda x: 0 if x['C']==\"\" else 1, axis=1).sum()\n",
    "print('Count reviews to send to API: ', count_reviews)\n",
    "print('Forecast cost of processing, usd: ', (count_reviews-5000)/1000*2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fbd5f0-5165-4929-bc5b-c9d9aafdda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_sentiment(text):\n",
    "    try:\n",
    "        client = language_v1.LanguageServiceClient.from_service_account_json(NL_SERVICE_ACCOUNT_JSON)\n",
    "        document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "        response = client.analyze_sentiment(document=document)\n",
    "        sentiment = response.document_sentiment\n",
    "        return sentiment.score, sentiment.magnitude\n",
    "    except Exception:\n",
    "        print('Error in def sentiment')  \n",
    "        return 'No', 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e83a3-a9ae-4052-bf44-e32b9e955e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_entities(text):\n",
    "    try:\n",
    "        client = language_v1.LanguageServiceClient.from_service_account_json(NL_SERVICE_ACCOUNT_JSON)\n",
    "        document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "        response = client.analyze_entities(document=document)\n",
    "        sss=[]\n",
    "        for entity in response.entities:\n",
    "            results = dict(\n",
    "                name=entity.name,\n",
    "                type=entity.type_.name,\n",
    "                salience=entity.salience,\n",
    "                wikipedia_url=entity.metadata.get(\"wikipedia_url\", \"-\"),\n",
    "                mid=entity.metadata.get(\"mid\", \"-\"),\n",
    "            )\n",
    "            sss.append(results)\n",
    "\n",
    "        return sss\n",
    "    except Exception:\n",
    "        print('Error in def entities')  \n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48deb2c-4dec-4f5b-9bf0-3593de8aaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_syntax(text):\n",
    "    try:\n",
    "        client = language_v1.LanguageServiceClient.from_service_account_json(NL_SERVICE_ACCOUNT_JSON)\n",
    "        document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "        response = client.analyze_syntax(document=document)\n",
    "\n",
    "        sent_count=len(response.sentences)\n",
    "        token_count=len(response.tokens)\n",
    "        sentlist=[]\n",
    "        for sentence in response.sentences:\n",
    "            sentlist.append(sentence.text.content)\n",
    "        tokenlist=[]    \n",
    "        for token in response.tokens:\n",
    "            results = dict(\n",
    "                token_text=token.text.content,\n",
    "                token_label=token.dependency_edge.label.name,\n",
    "                token_head_index=token.dependency_edge.head_token_index,\n",
    "                token_tag=token.part_of_speech.tag.name,\n",
    "                token_gender=token.part_of_speech.gender.name,\n",
    "                token_number=token.part_of_speech.number.name,\n",
    "                token_proper=token.part_of_speech.proper.name,\n",
    "                token_lemma=token.lemma,\n",
    "            )\n",
    "            tokenlist.append(results)    \n",
    "        return sent_count, token_count, sentlist, tokenlist\n",
    "    except Exception:\n",
    "        print('Error in def syntax')  \n",
    "        return 'No', 'No','No','No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08471c9-a4d8-48d8-be17-df11f692e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_for_nlp(message):\n",
    "    if len(message)<2:\n",
    "        return 0\n",
    "    else:\n",
    "        sent_score, sent_magnitude=analyze_text_sentiment(message) # two values \n",
    "        entities_list=analyze_text_entities(message) # list of dicts\n",
    "        sent_count, token_count, sentlist, tokenlist =analyze_text_syntax(message) \n",
    "        return sent_score, sent_magnitude, entities_list, sent_count, token_count, sentlist, tokenlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35ce73-1499-40ee-8dbc-9ee4772ddc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset divide into very small sections to be sent for processing and each save to file\n",
    "df['tmp']=np.nan\n",
    "for i in tqdm(range(1,100)):    \n",
    "    print('from ',(i-1)*1000, ' to ',i*1000)\n",
    "    print(df['review_id'][(i-1)*1000],'---',df['review_id'][i*1000],'---',df['review_id'][(i-1)*1000:i*1000].shape)\n",
    "    df['tmp'][(i-1)*1000:i*1000] = df['C'][(i-1)*1000:i*1000].progress_apply(get_text_for_nlp)\n",
    "    df5=df[['review_id','order_id','tmp']]\n",
    "    filename1='tmp'+str(i)+'.csv'\n",
    "    df5[(i-1)*1000:i*1000].to_csv(os.path.join(PATH, filename1), sep=';', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0a432-004d-4e7c-9c51-d1f910e51a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1='tmp_all.csv'\n",
    "df5.to_csv(os.path.join(PATH, filename1), sep=';', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53d277-4168-4dcb-b5ea-a08491381cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df.tmp.progress_apply(pd.Series) \n",
    "df3.rename(columns={0:'sent_score',1:'sent_magnitude', 2:'entities_list',3:'sentences_count',4:'token_count',5:'sentlist',6:'tokenlist'},  inplace=True)\n",
    "df4=pd.concat([df,df3],ignore_index=False, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
